{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collaborative Filter Recommendation System\n",
    "\n",
    "Paul Lim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# sklearn\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.utils.extmath import randomized_svd\n",
    "\n",
    "# Misc.\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_reviews_json(file, nth=1, limit=100):\n",
    "    '''\n",
    "    DESCRIBE:\n",
    "        - Extract the ratings/scores of reviews.\n",
    "    INPUT:\n",
    "        - file is the json file with the review information.\n",
    "        - nth determines whether to extract consecutive lines or skip lines.\n",
    "        - limit is the number of reviews to extract information from.\n",
    "    OUTPUT:\n",
    "        - df contains the extracted information.\n",
    "    '''   \n",
    "    user_list = []\n",
    "    biz_list = []\n",
    "    rating_list = []\n",
    "    useful_list = []\n",
    "    funny_list = []\n",
    "    cool_list = []\n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    with open(file) as f:\n",
    "        count = 0\n",
    "        for i, line in enumerate(f):\n",
    "            if count % nth == 0:\n",
    "                review_entry = json.loads(line)\n",
    "                user_list.append(review_entry['user_id'])\n",
    "                biz_list.append(review_entry['business_id'])\n",
    "                rating_list.append(review_entry['stars'])\n",
    "                useful_list.append(review_entry['useful'])\n",
    "                funny_list.append(review_entry['funny'])\n",
    "                cool_list.append(review_entry['cool'])\n",
    "                \n",
    "            if count > limit:\n",
    "                break\n",
    "            count += 1\n",
    "    df['user_id'] = user_list\n",
    "    df['business_id'] = biz_list\n",
    "    df['stars'] = rating_list\n",
    "    df['useful'] = useful_list\n",
    "    df['funny'] = funny_list\n",
    "    df['cool'] = cool_list\n",
    "    \n",
    "    return df\n",
    "\n",
    "def extract_business_names(file, nth=1, limit=100):\n",
    "    '''\n",
    "    DESCRIBE:\n",
    "        - Extracts the business names.\n",
    "    INPUT:\n",
    "        - file is the json file with the review information.\n",
    "        - nth determines whether to extract consecutive lines or skip lines.\n",
    "        - limit is the number of reviews to extract information from.\n",
    "    OUTPUT:\n",
    "        - df contains the extracted information.\n",
    "    ''' \n",
    "    city_list = []\n",
    "    state_list = []\n",
    "    biz_encrypt_list = []\n",
    "    biz_names_list = []\n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "    \n",
    "    with open(file) as f:\n",
    "        count = 0\n",
    "        for i, line in enumerate(f):\n",
    "            if count % nth == 0:\n",
    "                business_entry = json.loads(line)\n",
    "                \n",
    "                city_list.append(business_entry['city'])\n",
    "                state_list.append(business_entry['state'])\n",
    "                biz_encrypt_list.append(business_entry['business_id'])\n",
    "                biz_names_list.append(business_entry['name'])\n",
    "\n",
    "            if count > limit:\n",
    "                break\n",
    "            count += 1\n",
    "    df['city'] = city_list\n",
    "    df['state'] = state_list\n",
    "    df['name'] = biz_names_list\n",
    "    df['encrypt'] = biz_encrypt_list\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_recommendations(df, sample_inp, limit=10):\n",
    "    '''\n",
    "    DESCRIBE:\n",
    "        - Get the recommendations to businesses based on user input\n",
    "    INPUT:\n",
    "        - df is the dataframe with the cosine distances.\n",
    "        - sample_inp is the list of businesses the user is interested in.\n",
    "        - limit is the number of recommendations to return.\n",
    "    OUTPUT:\n",
    "        - sample_sum is a dataframe with the recommendations.\n",
    "    ''' \n",
    "    sample_sum = df[sample_inp].apply(lambda row: np.sum(row), axis=1)\n",
    "    sample_sum = sample_sum.sort_values(ascending=False)[:limit]\n",
    "    \n",
    "    return sample_sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the recommender system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "REVIEW_FILE_PATH = \"/home/plim0793/yelp_academic_dataset_review.json\"\n",
    "BUSINESS_FILE_PATH = \"/home/plim0793/yelp_academic_dataset_business.json\"\n",
    "\n",
    "sample = ['LongHorn Steakhouse', \"Flury's Cafe\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_reviews = extract_reviews_json(REVIEW_FILE_PATH, nth=1, limit=2000000)\n",
    "df_names = extract_business_names(BUSINESS_FILE_PATH, nth=1, limit=144072)\n",
    "\n",
    "df_tot = df_reviews.merge(df_names, how=\"left\", left_on=\"business_id\", right_on=\"encrypt\")\n",
    "df_tot = df_tot.drop('encrypt', axis=1)\n",
    "df_tot = df_tot.dropna()\n",
    "\n",
    "df_wide = pd.pivot_table(df_tot, values=['stars'],\n",
    "                                index=['name', 'user_id'],\n",
    "                                aggfunc=np.mean).unstack()\n",
    "\n",
    "df_wide_sample = df_wide.sample(frac=1)\n",
    "\n",
    "df_wide_sample = df_wide_sample.fillna(2.5)\n",
    "\n",
    "U, sig, VT = randomized_svd(df_wide_sample, \n",
    "                            n_components=10,\n",
    "                            n_iter=5)\n",
    "\n",
    "dists = cosine_similarity(U)\n",
    "\n",
    "df_dists = pd.DataFrame(dists, columns=df_wide_sample.index)\n",
    "df_dists.index = df_dists.columns\n",
    "\n",
    "recs = get_recommendations(df_dists, sample, limit=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/plim0793/fletcher/df_dists']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(df_dists, '/home/plim0793/fletcher/df_dists')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
