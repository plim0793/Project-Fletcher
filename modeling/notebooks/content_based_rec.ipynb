{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a Content-Based Recommender System\n",
    "\n",
    "Paul Lim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/plim0793/anaconda/lib/python3.5/site-packages/nltk/twitter/__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
      "  warnings.warn(\"The twython library has not been installed. \"\n"
     ]
    }
   ],
   "source": [
    "# Main imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import transformers\n",
    "\n",
    "# sklearn\n",
    "from sklearn.externals import joblib\n",
    "from sklearn import pipeline\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.neighbors import LSHForest\n",
    "\n",
    "# NLP \n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from textblob import TextBlob\n",
    "import spacy\n",
    "import gensim\n",
    "from gensim import models\n",
    "from gensim.models import word2vec\n",
    "import snowballstemmer\n",
    "\n",
    "# Misc.\n",
    "import re\n",
    "import datetime\n",
    "import time\n",
    "import logging\n",
    "import math\n",
    "\n",
    "% matplotlib inline\n",
    "\n",
    "sns.set_style(\"white\")\n",
    "sns.set_style('ticks')\n",
    "sns.set_style({'xtick.direction': u'in', 'ytick.direction': u'in'})\n",
    "sns.set_style({'legend.frameon': True})\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "handler = logging.FileHandler('logging_records.log')\n",
    "handler.setLevel(logging.INFO)\n",
    "\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "handler.setFormatter(formatter)\n",
    "\n",
    "logger.addHandler(handler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_dataframe():\n",
    "    '''\n",
    "    DESCRIBE:\n",
    "        - Split the dataframe by the word2vector columns and the ratings/names columns.\n",
    "    INPUT:\n",
    "        - No input.\n",
    "    OUTPUT:\n",
    "        - df_rn is the dataframe with the name, rating, and review text.\n",
    "        - df_300 is the dataframe with the 300 features from the word2vector model.\n",
    "    '''    \n",
    "    df = joblib.load(PATH_TO_DF)\n",
    "    df_rn = df[['name', 'rating', 'reviews']]\n",
    "    df_rn['name'] = df_rn['name'].apply(lambda x: re.sub('[0-9]*_', '', x))\n",
    "    \n",
    "    df_300 = df[[i for i in range(1,301)]]\n",
    "    \n",
    "    return df_rn, df_300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def modeling(df, model_obj):\n",
    "    '''\n",
    "    DESCRIBE:\n",
    "        - Fit the model with the dataframe.\n",
    "    INPUT:\n",
    "        - df is the dataframe with data.\n",
    "        - model_obj is the instantiated model object.\n",
    "    OUTPUT:\n",
    "        - model is the trained model object.\n",
    "    '''  \n",
    "    model = model_obj\n",
    "    model.fit(df)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_nearest(indices, distances, df):\n",
    "    '''\n",
    "    DESCRIBE:\n",
    "        - Sorts the closest reviews based on the distances.\n",
    "    INPUT:\n",
    "        - indices and distances are the values that determine how to sort the dataframe.\n",
    "        - df contains the data that is to be analyzed.\n",
    "    OUTPUT:\n",
    "        - df_temp is the sorted dataframe.\n",
    "    '''  \n",
    "    df_temp = df.loc[indices, ['rating','name','reviews']]\n",
    "    df_temp['dist'] = distances\n",
    "    df_temp = df_temp.sort_values(['dist'], ascending=False)\n",
    "    df_temp = df_temp.drop_duplicates()\n",
    "    df_temp = df_temp.reset_index()\n",
    "    return df_temp\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_recommendations(inp_str, pipeline, model, df, num_rec=20):\n",
    "    '''\n",
    "    DESCRIBE:\n",
    "        - Logs the top recommendations based on the input string.\n",
    "    INPUT:\n",
    "        - inp_str is the preferences inputted by the user.\n",
    "        - pipeline is the pipeline that transforms the user input into the same vector space as the model.\n",
    "        - model is the trained model.\n",
    "        - df is the dataframe with the data to be analyzed.\n",
    "        - num_rec is the number of recommendations to log.\n",
    "    OUTPUT:\n",
    "        - df_sample_rec is the dataframe that contains the recommendations.\n",
    "    '''  \n",
    "    if isinstance(inp_str, str):\n",
    "        input_as_list = [inp_str]\n",
    "        sample_df = pd.DataFrame(input_as_list, columns=[\"sample\"])\n",
    "        sample_transform = pipeline.fit_transform(sample_df)\n",
    "        \n",
    "        dist, indices = model.kneighbors(sample_transform, n_neighbors=num_rec)\n",
    "        df_sample_rec = get_nearest(indices[0], dist[0], df)\n",
    "        \n",
    "        for i in range(len(df_sample_rec)):\n",
    "            logging.info(str(df_sample_rec.loc[i, 'name']))\n",
    "            logging.info(\"NUMBER \" + str(i) + \": \", str(df_sample_rec.loc[i, 'reviews']))\n",
    "            logging.info(\"\\n\")\n",
    "        \n",
    "        return df_sample_rec\n",
    "    else:\n",
    "        logging.warning('Input was not a string')\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Content-Based Recommender System\n",
    "\n",
    "### This recommender is based on Yelp reviews on cafes near the San Francisco Bay Area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-06-01 16:47:03,016 : INFO : loading projection weights from ~/Documents/GoogleNews-vectors-negative300.bin.gz\n",
      "2017-06-01 16:50:28,675 : INFO : loaded (3000000, 300) matrix from ~/Documents/GoogleNews-vectors-negative300.bin.gz\n"
     ]
    }
   ],
   "source": [
    "# ONLY RUN ONCE AT THE START OF THE KERNEL\n",
    "w2v = models.KeyedVectors.load_word2vec_format(\"~/Documents/GoogleNews-vectors-negative300.bin.gz\",binary=True)\n",
    "PATH_TO_DF = '../data/df_out'\n",
    "\n",
    "sample_input = \"good coffee and quiet setting and fast wifi\"\n",
    "\n",
    "PIPELINE = Pipeline([\n",
    "    ('split_text', transformers.SeparateFeaturesTransformer(text_cols=['sample'])),\n",
    "    ('clean', transformers.CleanTextTransformer('sample')),\n",
    "    ('sentiment', transformers.SentimentTransformer(text_col='clean_reviews')),\n",
    "    ('vectorize', transformers.Word2VecTransformer(text_col='clean_reviews', w2v=w2v))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_rn, df_300 = split_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_sample_rec = get_recommendations(sample_input, PIPELINE, model, df_rn, num_rec=20)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
