{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling Yelp Reviews of Cafes Near San Francisco\n",
    "\n",
    "Paul Lim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "\n",
    "# sklearn\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn import pipeline, feature_selection, decomposition\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.cluster import DBSCAN, AgglomerativeClustering, Birch\n",
    "from sklearn.decomposition import PCA, NMF\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# NLP \n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from textblob import TextBlob\n",
    "import spacy\n",
    "import gensim\n",
    "from gensim import models\n",
    "from gensim.models import word2vec\n",
    "import snowballstemmer\n",
    "\n",
    "# Misc.\n",
    "import re\n",
    "import datetime\n",
    "import time\n",
    "import logging\n",
    "import math\n",
    "\n",
    "% matplotlib inline\n",
    "\n",
    "sns.set_style(\"white\")\n",
    "sns.set_style('ticks')\n",
    "sns.set_style({'xtick.direction': u'in', 'ytick.direction': u'in'})\n",
    "sns.set_style({'legend.frameon': True})\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running List of Functions/Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DataframeToSeriesTransformer(BaseEstimator, TransformerMixin):\n",
    "        \n",
    "    def __init__(self, col=None):\n",
    "        self.col = col\n",
    "    \n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        if self.col:\n",
    "            print(\"DTST: \", X[self.col].shape)\n",
    "            return X[self.col]\n",
    "        else:\n",
    "            return X\n",
    "        \n",
    "class SeparateFeaturesTransformer(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, num_cols=None, text_cols=None):\n",
    "        self.num_cols = num_cols\n",
    "        self.text_cols = text_cols\n",
    "        \n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        if self.num_cols:\n",
    "            print(\"SFT: \", X.loc[:, self.num_cols].shape)\n",
    "            return X.loc[:, self.num_cols]\n",
    "        elif self.text_cols:\n",
    "            print(\"SFT: \", X.loc[:, self.text_cols].shape)\n",
    "            return X.loc[:, self.text_cols]\n",
    "        else:\n",
    "            return X\n",
    "        \n",
    "class CleanTextTransformer(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self, text_col=None):\n",
    "        self.text_col = text_col\n",
    "        \n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X_list = X.loc[:, self.text_col].tolist()\n",
    "        \n",
    "        if self.text_col:\n",
    "            df = pd.DataFrame()\n",
    "            clean_review_list = []\n",
    "            \n",
    "            for review in X_list:\n",
    "                clean_review = ''\n",
    "                \n",
    "                for word in TextBlob(review).words:\n",
    "                    clean_review += word.lemmatize() + ' '\n",
    "                        \n",
    "                clean_review_list.append(clean_review)\n",
    "                        \n",
    "            df['clean_reviews'] = clean_review_list\n",
    "            print(\"CTT: \", df.shape)\n",
    "            return df\n",
    "        else:\n",
    "            return X\n",
    "        \n",
    "class DensifyTransformer(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        df = pd.DataFrame(X.toarray())\n",
    "        print(\"DT: \", df.shape)\n",
    "        return df\n",
    "    \n",
    "class SentimentTransformer(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, text_col=None):\n",
    "        self.text_col = text_col\n",
    "    \n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        if self.text_col:\n",
    "            df = pd.DataFrame()\n",
    "            sum_pol_list = []\n",
    "            sum_sub_list = []\n",
    "            doc_list = X.loc[:, self.text_col].tolist()\n",
    "\n",
    "            for doc in doc_list:\n",
    "                sum_pol = 0\n",
    "                sum_sub = 0\n",
    "                doc_blob = TextBlob(doc)\n",
    "\n",
    "                for sent in doc_blob.sentences:\n",
    "                    sum_pol += sent.sentiment[0]\n",
    "                    sum_sub += sent.sentiment[1]\n",
    "\n",
    "                sum_pol_list.append(sum_pol)\n",
    "                sum_sub_list.append(sum_sub)\n",
    "\n",
    "            df['pol'] = sum_pol_list\n",
    "            df['sub'] = sum_sub_list\n",
    "            df['clean_reviews'] = X.loc[:, self.text_col] # Need to keep the clean reviews for the W2V transformer.\n",
    "            print(\"ST: \", df.shape)\n",
    "            return df\n",
    "        else:\n",
    "            return X\n",
    "\n",
    "class Word2VecTransformer(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, text_col=None, w2v=None):\n",
    "        self.text_col = text_col\n",
    "        self.w2v = w2v\n",
    "        \n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        if self.text_col:\n",
    "            avg_w2v_list = []\n",
    "            review_list = X.loc[:, self.text_col].tolist()\n",
    "            \n",
    "            for review in review_list:\n",
    "                avg_w2v = np.zeros(300)\n",
    "                count = 0\n",
    "                \n",
    "                for word in review:\n",
    "                    try:\n",
    "                        avg_w2v += w2v.word_vec(word)\n",
    "                        count += 1\n",
    "                    except Exception:\n",
    "                        continue\n",
    "\n",
    "                avg_w2v_list.append(avg_w2v/count)\n",
    "            df = pd.DataFrame(avg_w2v_list)\n",
    "            print(\"W2V: \", df.shape)\n",
    "            return df\n",
    "        else:\n",
    "            return X\n",
    "        \n",
    "class ToDataFrameTransformer(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        df = pd.DataFrame(X)\n",
    "        print(\"TDFT: \", df.shape)\n",
    "        return df\n",
    "        \n",
    "class DropTextTransformer(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, text_col=None):\n",
    "        self.text_col = text_col\n",
    "        \n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        if self.text_col:\n",
    "            df = X.drop(self.text_col, axis=1)\n",
    "            print(\"DTT: \", df.shape)\n",
    "            return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_df():\n",
    "    '''\n",
    "    DESCRIBE:\n",
    "        - Preprocesses the data.\n",
    "    INPUT:\n",
    "        - df is the dataframe that needs to be cleaned.\n",
    "    OUTPUT:\n",
    "        - The dataframe that is outputted has the columns reordered and data types changed.\n",
    "    '''\n",
    "    if os.path.isfile(PATH_TO_DATA):\n",
    "        df = joblib.load(PATH_TO_DATA)\n",
    "    else:\n",
    "        print(\"Invalid path to data\")\n",
    "        return False\n",
    "    \n",
    "    df = df[['name', 'rating' ,'reviews']]\n",
    "    df['rating'] = df['rating'].apply(lambda x: int(x))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit_model(pipe, model, df_orig):\n",
    "    '''\n",
    "    DESCRIBE:\n",
    "        - Fit the model through the pipeline and get scoring metrics for the model.\n",
    "    INPUT:\n",
    "        - pipe is the pipeline to run the data through.\n",
    "        - model is the model object that will be used to fit the data.\n",
    "        - df_orig is the data.\n",
    "    OUTPUT:\n",
    "        - df_transformed is the dataframe that is outputted from the pipeline.\n",
    "        - pred is the predictions for the data for this particular model.\n",
    "    '''\n",
    "    df_transformed = pipe.fit_transform(df_orig)\n",
    "    pred = model.fit_predict(df_transformed)\n",
    "    print(\"Number of Clusters: \", len(np.unique(pred)))\n",
    "    if len(np.unique(model.labels_)) > 1:\n",
    "        print(\"Silhouette Coefficient: %0.3f\" % silhouette_score(df_transformed, model.labels_))\n",
    "    return df_transformed, pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_metrics(model_dict, pipe, df):\n",
    "    '''\n",
    "    DESCRIBE:\n",
    "        - Fits a dictionary of models through the pipeline and get scoring metrics for the models.\n",
    "    INPUT:\n",
    "        - pipe is the pipeline to run the data through.\n",
    "        - model_dict is a dictionary of the model objects that will be used to fit the data.\n",
    "        - df is the data.\n",
    "    OUTPUT:\n",
    "        - model_dfs contains the transformed dataframe and scoring metric for each model.\n",
    "    '''\n",
    "    model_dfs = {}\n",
    "    for name, model in model_dict.items():\n",
    "        print(name)\n",
    "        temp_df, temp_score = fit_model(pipe, model, df)\n",
    "        model_dfs[name] = [temp_df, temp_score]\n",
    "    return model_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_feature_space(df, transformed_df, path):\n",
    "    '''\n",
    "    DESCRIBE:\n",
    "        - Adds the feature space that was produced by the W2V model to the original dataframe.\n",
    "    INPUT:\n",
    "        - df is the data.\n",
    "        - transformed_df is the dataframe containing the transformed data.\n",
    "        - path where the dataframe should be saved.\n",
    "    OUTPUT:\n",
    "        - df_out is the dataframe with the new features appended.\n",
    "    '''\n",
    "    df_out = pd.DataFrame(transformed_df, columns=['rating'] + [i for i in range(1,301)])\n",
    "    df_out['name'] = df_out['name'].tolist()\n",
    "    df_out['reviews'] = df_out['reviews'].tolist()\n",
    "    \n",
    "    if not os.path.isdir(path):\n",
    "        os.mkdir(path)\n",
    "\n",
    "    joblib.dump(df_out, os.path.join(path, str(df_out)))\n",
    "    \n",
    "    return df_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "global PATH_TO_DATA = '../data/df_tot'\n",
    "global w2v = models.KeyedVectors.load_word2vec_format(\"~/Documents/GoogleNews-vectors-negative300.bin.gz\",binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = clean_df()\n",
    "\n",
    "pipe = Pipeline([\n",
    "                    ('text_feat', Pipeline([\n",
    "\n",
    "                        ('split_text', SeparateFeaturesTransformer(text_cols=['reviews'])),\n",
    "                        ('clean', CleanTextTransformer('reviews')),\n",
    "                        ('sentiment', SentimentTransformer(text_col='clean_reviews')),\n",
    "                        ('vectorize', Word2VecTransformer(text_col='clean_reviews', w2v=w2v))\n",
    "                                            ]))\n",
    "                    ])\n",
    "\n",
    "model_dict = {\n",
    "    \"agg\": AgglomerativeClustering(n_clusters=5,\n",
    "                                   affinity=\"cosine\",\n",
    "                                   linkage=\"complete\"),\n",
    "    \"birch\": Birch(threshold=0.5,\n",
    "                   n_clusters=5,\n",
    "                   branching_factor=50),\n",
    "    \"db\": DBSCAN(eps=0.5,\n",
    "                 min_samples=10,\n",
    "                 metric=\"euclidean\")\n",
    "}\n",
    "\n",
    "model_metrics_dict = model_metrics(model_dict, pipe, df)\n",
    "df_out = add_feature_space(df, model_metrics_dict_W2V['birch'][0], '../data/')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
