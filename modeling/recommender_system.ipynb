{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a Recommender System\n",
    "\n",
    "Paul Lim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Main imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "\n",
    "# sklearn\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics.pairwise import manhattan_distances\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from sklearn.externals import joblib\n",
    "from sklearn import pipeline, feature_selection, decomposition\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.cluster import DBSCAN, AgglomerativeClustering, Birch\n",
    "from sklearn.neighbors import NearestNeighbors, LSHForest\n",
    "\n",
    "# NLP \n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from textblob import TextBlob\n",
    "import spacy\n",
    "import gensim\n",
    "from gensim import models\n",
    "from gensim.models import word2vec\n",
    "import snowballstemmer\n",
    "\n",
    "# Misc.\n",
    "import re\n",
    "import datetime\n",
    "import time\n",
    "import logging\n",
    "import math\n",
    "\n",
    "% matplotlib inline\n",
    "\n",
    "sns.set_style(\"white\")\n",
    "sns.set_style('ticks')\n",
    "sns.set_style({'xtick.direction': u'in', 'ytick.direction': u'in'})\n",
    "sns.set_style({'legend.frameon': True})\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions/Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class DataframeToSeriesTransformer(BaseEstimator, TransformerMixin):\n",
    "        \n",
    "    def __init__(self, col=None):\n",
    "        self.col = col\n",
    "    \n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        if self.col:\n",
    "            print(\"DTST: \", X[self.col].shape)\n",
    "            return X[self.col]\n",
    "        else:\n",
    "            return X\n",
    "        \n",
    "class SeparateFeaturesTransformer(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, num_cols=None, text_cols=None):\n",
    "        self.num_cols = num_cols\n",
    "        self.text_cols = text_cols\n",
    "        \n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        if self.num_cols:\n",
    "            print(\"SFT: \", X.loc[:, self.num_cols].shape)\n",
    "            return X.loc[:, self.num_cols]\n",
    "        elif self.text_cols:\n",
    "            print(\"SFT: \", X.loc[:, self.text_cols].shape)\n",
    "            return X.loc[:, self.text_cols]\n",
    "        else:\n",
    "            return X\n",
    "        \n",
    "class WilsonAverageTransformer(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, num_col=None, biz_list=None):\n",
    "        self.num_col = num_col\n",
    "        self.biz_list = biz_list\n",
    "    \n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        if self.num_col and self.biz_list.all():\n",
    "            scores = get_average_rating(X, self.biz_list)\n",
    "            \n",
    "            X_avg = pd.DataFrame({'average': scores})\n",
    "            print(\"WAT: \", X_avg.shape)\n",
    "            return X_avg\n",
    "        else:\n",
    "            return X\n",
    "        \n",
    "class CleanTextTransformer(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self, text_col=None):\n",
    "        self.text_col = text_col\n",
    "        \n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "#         NLP = spacy.load('en')\n",
    "        stemmer = snowballstemmer.EnglishStemmer()\n",
    "        stop = stopwords.words('english')\n",
    "        stop_list = stemmer.stemWords(stop)\n",
    "        stop_list = set(stop_list)\n",
    "        stop = set(stop + list(stop_list))\n",
    "        \n",
    "        if self.text_col:\n",
    "            df = pd.DataFrame()\n",
    "            clean_review_list = []\n",
    "            \n",
    "            for review in X.loc[:, self.text_col]:\n",
    "                clean_review = ''\n",
    "                \n",
    "                for word in TextBlob(review).words:\n",
    "                    if word not in stop:\n",
    "                        clean_review += word.lemmatize() + ' '\n",
    "                        \n",
    "#                 clean_review = NLP(clean_review)\n",
    "                clean_review_list.append(clean_review)\n",
    "                        \n",
    "            df['clean_reviews'] = clean_review_list\n",
    "            print(\"CTT: \", df.shape)\n",
    "            return df\n",
    "        else:\n",
    "            return X\n",
    "        \n",
    "class DensifyTransformer(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        df = pd.DataFrame(X.toarray())\n",
    "        print(\"DT: \", df.shape)\n",
    "        return df\n",
    "    \n",
    "class SentimentTransformer(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, text_col=None):\n",
    "        self.text_col = text_col\n",
    "    \n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        if self.text_col:\n",
    "            df = pd.DataFrame()\n",
    "            sum_pol_list = []\n",
    "            sum_sub_list = []\n",
    "\n",
    "            for doc in X.loc[:, self.text_col]:\n",
    "                sum_pol = 0\n",
    "                sum_sub = 0\n",
    "                doc_blob = TextBlob(doc)\n",
    "\n",
    "                for sent in doc_blob.sentences:\n",
    "                    sum_pol += sent.sentiment[0]\n",
    "                    sum_sub += sent.sentiment[1]\n",
    "\n",
    "                sum_pol_list.append(sum_pol)\n",
    "                sum_sub_list.append(sum_sub)\n",
    "\n",
    "            df['pol'] = sum_pol_list\n",
    "            df['sub'] = sum_sub_list\n",
    "            df['clean_reviews'] = X.loc[:, self.text_col] # Need to keep the clean reviews for the W2V transformer.\n",
    "            print(\"ST: \", df.shape)\n",
    "            return df\n",
    "        else:\n",
    "            return X\n",
    "\n",
    "class Word2VecTransformer(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, text_col=None, w2v=None):\n",
    "        self.text_col = text_col\n",
    "        self.w2v = w2v\n",
    "        \n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        if self.text_col:\n",
    "            avg_w2v_list = []\n",
    "            \n",
    "            for review in X.loc[:, self.text_col]:\n",
    "                avg_w2v = np.zeros(300)\n",
    "                count = 0\n",
    "                \n",
    "                for word in review:\n",
    "                    try:\n",
    "                        avg_w2v += w2v.word_vec(word)\n",
    "                        count += 1\n",
    "                    except Exception:\n",
    "                        continue\n",
    "\n",
    "                avg_w2v_list.append(avg_w2v/count)\n",
    "            df = pd.DataFrame(avg_w2v_list)\n",
    "#             print(df.head())\n",
    "            print(\"W2V: \", df.shape)\n",
    "            return df\n",
    "        else:\n",
    "            return X\n",
    "        \n",
    "class ToDataFrameTransformer(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        df = pd.DataFrame(X)\n",
    "#         print(df.head())\n",
    "        print(\"TDFT: \", df.shape)\n",
    "        return df\n",
    "        \n",
    "class DropTextTransformer(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, text_col=None):\n",
    "        self.text_col = text_col\n",
    "        \n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        if self.text_col:\n",
    "            df = X.drop(self.text_col, axis=1)\n",
    "            print(\"DTT: \", df.shape)\n",
    "            return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Content-Based Recommender System\n",
    "\n",
    "### This recommender is based on Yelp reviews on cafes near the San Francisco Bay Area"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_best = joblib.load('../data/df_best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "      <th>300</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.171138</td>\n",
       "      <td>0.110859</td>\n",
       "      <td>0.007889</td>\n",
       "      <td>0.148174</td>\n",
       "      <td>-0.032908</td>\n",
       "      <td>0.011566</td>\n",
       "      <td>-0.097138</td>\n",
       "      <td>-0.047231</td>\n",
       "      <td>-0.034002</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.023892</td>\n",
       "      <td>-0.113161</td>\n",
       "      <td>0.081303</td>\n",
       "      <td>-0.028848</td>\n",
       "      <td>-0.163551</td>\n",
       "      <td>-0.096561</td>\n",
       "      <td>-0.006837</td>\n",
       "      <td>-0.096540</td>\n",
       "      <td>0.170566</td>\n",
       "      <td>0_FourBarrelCoffee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>-0.148333</td>\n",
       "      <td>0.119471</td>\n",
       "      <td>0.008990</td>\n",
       "      <td>0.129535</td>\n",
       "      <td>-0.040324</td>\n",
       "      <td>0.018529</td>\n",
       "      <td>-0.110370</td>\n",
       "      <td>-0.052895</td>\n",
       "      <td>-0.063144</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.020208</td>\n",
       "      <td>-0.116654</td>\n",
       "      <td>0.091738</td>\n",
       "      <td>-0.026030</td>\n",
       "      <td>-0.148781</td>\n",
       "      <td>-0.113272</td>\n",
       "      <td>-0.010141</td>\n",
       "      <td>-0.115695</td>\n",
       "      <td>0.145180</td>\n",
       "      <td>0_FourBarrelCoffee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.165882</td>\n",
       "      <td>0.112039</td>\n",
       "      <td>0.012008</td>\n",
       "      <td>0.131343</td>\n",
       "      <td>-0.039475</td>\n",
       "      <td>0.021509</td>\n",
       "      <td>-0.101088</td>\n",
       "      <td>-0.057847</td>\n",
       "      <td>-0.044514</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006879</td>\n",
       "      <td>-0.099389</td>\n",
       "      <td>0.094930</td>\n",
       "      <td>-0.028523</td>\n",
       "      <td>-0.151354</td>\n",
       "      <td>-0.106891</td>\n",
       "      <td>-0.015555</td>\n",
       "      <td>-0.115064</td>\n",
       "      <td>0.156558</td>\n",
       "      <td>0_FourBarrelCoffee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.182368</td>\n",
       "      <td>0.110774</td>\n",
       "      <td>0.002860</td>\n",
       "      <td>0.140167</td>\n",
       "      <td>-0.051075</td>\n",
       "      <td>0.016756</td>\n",
       "      <td>-0.095475</td>\n",
       "      <td>-0.046202</td>\n",
       "      <td>-0.047613</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.014586</td>\n",
       "      <td>-0.103274</td>\n",
       "      <td>0.082766</td>\n",
       "      <td>-0.033930</td>\n",
       "      <td>-0.157451</td>\n",
       "      <td>-0.109556</td>\n",
       "      <td>-0.020041</td>\n",
       "      <td>-0.106313</td>\n",
       "      <td>0.154082</td>\n",
       "      <td>0_FourBarrelCoffee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>-0.159966</td>\n",
       "      <td>0.105777</td>\n",
       "      <td>0.004223</td>\n",
       "      <td>0.132470</td>\n",
       "      <td>-0.050917</td>\n",
       "      <td>0.013202</td>\n",
       "      <td>-0.092117</td>\n",
       "      <td>-0.073106</td>\n",
       "      <td>-0.037257</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003893</td>\n",
       "      <td>-0.098995</td>\n",
       "      <td>0.088994</td>\n",
       "      <td>-0.037172</td>\n",
       "      <td>-0.156656</td>\n",
       "      <td>-0.102626</td>\n",
       "      <td>-0.017717</td>\n",
       "      <td>-0.094929</td>\n",
       "      <td>0.141094</td>\n",
       "      <td>0_FourBarrelCoffee</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 302 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   rating         1         2         3         4         5         6  \\\n",
       "0     4.0 -0.171138  0.110859  0.007889  0.148174 -0.032908  0.011566   \n",
       "1     5.0 -0.148333  0.119471  0.008990  0.129535 -0.040324  0.018529   \n",
       "2     4.0 -0.165882  0.112039  0.012008  0.131343 -0.039475  0.021509   \n",
       "3     2.0 -0.182368  0.110774  0.002860  0.140167 -0.051075  0.016756   \n",
       "4     5.0 -0.159966  0.105777  0.004223  0.132470 -0.050917  0.013202   \n",
       "\n",
       "          7         8         9         ...               292       293  \\\n",
       "0 -0.097138 -0.047231 -0.034002         ...         -0.023892 -0.113161   \n",
       "1 -0.110370 -0.052895 -0.063144         ...         -0.020208 -0.116654   \n",
       "2 -0.101088 -0.057847 -0.044514         ...         -0.006879 -0.099389   \n",
       "3 -0.095475 -0.046202 -0.047613         ...         -0.014586 -0.103274   \n",
       "4 -0.092117 -0.073106 -0.037257         ...          0.003893 -0.098995   \n",
       "\n",
       "        294       295       296       297       298       299       300  \\\n",
       "0  0.081303 -0.028848 -0.163551 -0.096561 -0.006837 -0.096540  0.170566   \n",
       "1  0.091738 -0.026030 -0.148781 -0.113272 -0.010141 -0.115695  0.145180   \n",
       "2  0.094930 -0.028523 -0.151354 -0.106891 -0.015555 -0.115064  0.156558   \n",
       "3  0.082766 -0.033930 -0.157451 -0.109556 -0.020041 -0.106313  0.154082   \n",
       "4  0.088994 -0.037172 -0.156656 -0.102626 -0.017717 -0.094929  0.141094   \n",
       "\n",
       "                 name  \n",
       "0  0_FourBarrelCoffee  \n",
       "1  0_FourBarrelCoffee  \n",
       "2  0_FourBarrelCoffee  \n",
       "3  0_FourBarrelCoffee  \n",
       "4  0_FourBarrelCoffee  \n",
       "\n",
       "[5 rows x 302 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_best.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Separate the rating and name columns from the 300 dimensional space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_rn = df_best[['name', 'rating']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_300 = df_best[[i for i in range(1,301)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "arr_300 = np.array(df_300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the Google word2vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-05-26 18:26:41,968 : INFO : loading projection weights from ~/Documents/GoogleNews-vectors-negative300.bin.gz\n",
      "2017-05-26 18:29:29,513 : INFO : loaded (3000000, 300) matrix from ~/Documents/GoogleNews-vectors-negative300.bin.gz\n"
     ]
    }
   ],
   "source": [
    "# ONLY RUN ONCE AT THE START OF THE KERNEL\n",
    "# w2v = models.KeyedVectors.load_word2vec_format(\"~/Documents/GoogleNews-vectors-negative300.bin.gz\",binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the pipeline to fit and transform the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pipe_w2v = Pipeline([\n",
    "                    ('combined_features', FeatureUnion([\n",
    "\n",
    "                        ('num_feat', SeparateFeaturesTransformer(num_cols=['rating'])),\n",
    "                        ('text_feat', Pipeline([\n",
    "\n",
    "                            ('split_text', SeparateFeaturesTransformer(text_cols=['reviews'])),\n",
    "                            ('clean', CleanTextTransformer('reviews')),\n",
    "                            ('sentiment', SentimentTransformer(text_col='clean_reviews')),\n",
    "                            ('vectorize', Word2VecTransformer(text_col='clean_reviews', w2v=w2v))\n",
    "                                                ]))\n",
    "                                                        ]))\n",
    "                    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the LSH Forest algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lsh = LSHForest(n_neighbors=5, n_estimators=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSHForest(min_hash_match=4, n_candidates=50, n_estimators=50, n_neighbors=5,\n",
       "     radius=1.0, radius_cutoff_ratio=0.9, random_state=None)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsh.fit(df_300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Provide a sample input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sample_input = [\"good light roast and quiet atmosphere\"]\n",
    "sample_df = pd.DataFrame(sample_input, columns=[\"sample\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the pipeline to fit and transform the sample input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipe_sample = Pipeline([\n",
    "                        ('split_text', SeparateFeaturesTransformer(text_cols=['sample'])),\n",
    "                        ('clean', CleanTextTransformer('sample')),\n",
    "                        ('sentiment', SentimentTransformer(text_col='clean_reviews')),\n",
    "                        ('vectorize', Word2VecTransformer(text_col='clean_reviews', w2v=w2v))\n",
    "                                            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SFT:  (1, 1)\n",
      "CTT:  (1, 1)\n",
      "ST:  (1, 3)\n",
      "W2V:  (1, 300)\n"
     ]
    }
   ],
   "source": [
    "sample_transform = pipe_sample.fit_transform(sample_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the 20 nearest reviews for a sample input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "distances, indices = lsh.kneighbors(sample_transform, n_neighbors=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_nearest(indices, df):\n",
    "    df_temp = df.loc[indices, ['rating','name']]\n",
    "    df_temp_grouped = df_temp.groupby(['name']).mean().reset_index()\n",
    "    return df_temp_grouped\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>103_CoffeeCultures</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>131_farm:table</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>163_HoleInTheWallCoffee</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32_CafeStJorge</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>334_1428HAIGHTPatioCafe&amp;Crepery</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>40_Bernie’s</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>426_DandelionChocolate</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>427_Nectar</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>450_Bancarella</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>480_CafePrague</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>485_PeasantPiesCafé&amp;Catering</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>506_Outerlands</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>525_SausalitoCafe1stSt</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>598_Foodhall</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>627_H2OCafe</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>695_Peet’sCoffee</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>698_TheChaiCart</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>733_AABakery&amp;Cafe</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>80_Joy’sPlace</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               name  rating\n",
       "0                103_CoffeeCultures     5.0\n",
       "1                    131_farm:table     5.0\n",
       "2           163_HoleInTheWallCoffee     5.0\n",
       "3                    32_CafeStJorge     4.0\n",
       "4   334_1428HAIGHTPatioCafe&Crepery     5.0\n",
       "5                       40_Bernie’s     4.0\n",
       "6            426_DandelionChocolate     4.0\n",
       "7                        427_Nectar     3.0\n",
       "8                    450_Bancarella     3.0\n",
       "9                    480_CafePrague     4.0\n",
       "10     485_PeasantPiesCafé&Catering     5.0\n",
       "11                   506_Outerlands     4.0\n",
       "12           525_SausalitoCafe1stSt     5.0\n",
       "13                     598_Foodhall     5.0\n",
       "14                      627_H2OCafe     1.0\n",
       "15                 695_Peet’sCoffee     2.0\n",
       "16                  698_TheChaiCart     3.0\n",
       "17                733_AABakery&Cafe     4.0\n",
       "18                    80_Joy’sPlace     4.0"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_nearest(indices[0], df_rn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
