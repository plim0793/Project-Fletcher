{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a Content-Based Recommender System\n",
    "\n",
    "Paul Lim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/plim0793/anaconda/lib/python3.5/site-packages/nltk/twitter/__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
      "  warnings.warn(\"The twython library has not been installed. \"\n"
     ]
    }
   ],
   "source": [
    "# Main imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "\n",
    "# sklearn\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics.pairwise import manhattan_distances\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from sklearn.externals import joblib\n",
    "from sklearn import pipeline, feature_selection, decomposition\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.cluster import DBSCAN, AgglomerativeClustering, Birch\n",
    "from sklearn.neighbors import NearestNeighbors, LSHForest\n",
    "\n",
    "# NLP \n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from textblob import TextBlob\n",
    "import spacy\n",
    "import gensim\n",
    "from gensim import models\n",
    "from gensim.models import word2vec\n",
    "import snowballstemmer\n",
    "\n",
    "# Misc.\n",
    "import re\n",
    "import datetime\n",
    "import time\n",
    "import logging\n",
    "import math\n",
    "\n",
    "% matplotlib inline\n",
    "\n",
    "sns.set_style(\"white\")\n",
    "sns.set_style('ticks')\n",
    "sns.set_style({'xtick.direction': u'in', 'ytick.direction': u'in'})\n",
    "sns.set_style({'legend.frameon': True})\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions/Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class DataframeToSeriesTransformer(BaseEstimator, TransformerMixin):\n",
    "        \n",
    "    def __init__(self, col=None):\n",
    "        self.col = col\n",
    "    \n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        if self.col:\n",
    "            print(\"DTST: \", X[self.col].shape)\n",
    "            return X[self.col]\n",
    "        else:\n",
    "            return X\n",
    "        \n",
    "class SeparateFeaturesTransformer(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, num_cols=None, text_cols=None):\n",
    "        self.num_cols = num_cols\n",
    "        self.text_cols = text_cols\n",
    "        \n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        if self.num_cols:\n",
    "            print(\"SFT: \", X.loc[:, self.num_cols].shape)\n",
    "            return X.loc[:, self.num_cols]\n",
    "        elif self.text_cols:\n",
    "            print(\"SFT: \", X.loc[:, self.text_cols].shape)\n",
    "            return X.loc[:, self.text_cols]\n",
    "        else:\n",
    "            return X\n",
    "        \n",
    "class WilsonAverageTransformer(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, num_col=None, biz_list=None):\n",
    "        self.num_col = num_col\n",
    "        self.biz_list = biz_list\n",
    "    \n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        if self.num_col and self.biz_list.all():\n",
    "            scores = get_average_rating(X, self.biz_list)\n",
    "            \n",
    "            X_avg = pd.DataFrame({'average': scores})\n",
    "            print(\"WAT: \", X_avg.shape)\n",
    "            return X_avg\n",
    "        else:\n",
    "            return X\n",
    "        \n",
    "class CleanTextTransformer(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self, text_col=None):\n",
    "        self.text_col = text_col\n",
    "        \n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "\n",
    "        X_list = X.loc[:, self.text_col].tolist()\n",
    "        \n",
    "        if self.text_col:\n",
    "            df = pd.DataFrame()\n",
    "            clean_review_list = []\n",
    "            \n",
    "            for review in X_list:\n",
    "                clean_review = ''\n",
    "                \n",
    "                for word in TextBlob(review).words:\n",
    "                    clean_review += word.lemmatize() + ' '\n",
    "                        \n",
    "                clean_review_list.append(clean_review)\n",
    "                        \n",
    "            df['clean_reviews'] = clean_review_list\n",
    "            print(\"CTT: \", df.shape)\n",
    "            return df\n",
    "        else:\n",
    "            return X\n",
    "        \n",
    "class DensifyTransformer(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        df = pd.DataFrame(X.toarray())\n",
    "        print(\"DT: \", df.shape)\n",
    "        return df\n",
    "    \n",
    "class SentimentTransformer(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, text_col=None):\n",
    "        self.text_col = text_col\n",
    "    \n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        if self.text_col:\n",
    "            df = pd.DataFrame()\n",
    "            sum_pol_list = []\n",
    "            sum_sub_list = []\n",
    "\n",
    "            for doc in X.loc[:, self.text_col]:\n",
    "                sum_pol = 0\n",
    "                sum_sub = 0\n",
    "                doc_blob = TextBlob(doc)\n",
    "\n",
    "                for sent in doc_blob.sentences:\n",
    "                    sum_pol += sent.sentiment[0]\n",
    "                    sum_sub += sent.sentiment[1]\n",
    "\n",
    "                sum_pol_list.append(sum_pol)\n",
    "                sum_sub_list.append(sum_sub)\n",
    "\n",
    "            df['pol'] = sum_pol_list\n",
    "            df['sub'] = sum_sub_list\n",
    "            df['clean_reviews'] = X.loc[:, self.text_col] # Need to keep the clean reviews for the W2V transformer.\n",
    "            print(\"ST: \", df.shape)\n",
    "            return df\n",
    "        else:\n",
    "            return X\n",
    "\n",
    "class Word2VecTransformer(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, text_col=None, w2v=None):\n",
    "        self.text_col = text_col\n",
    "        self.w2v = w2v\n",
    "        \n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        if self.text_col:\n",
    "            avg_w2v_list = []\n",
    "            \n",
    "            for review in X.loc[:, self.text_col]:\n",
    "                avg_w2v = np.zeros(300)\n",
    "                count = 0\n",
    "                \n",
    "                for word in review:\n",
    "                    try:\n",
    "                        avg_w2v += w2v.word_vec(word)\n",
    "                        count += 1\n",
    "                    except Exception:\n",
    "                        continue\n",
    "\n",
    "                avg_w2v_list.append(avg_w2v/count)\n",
    "            df = pd.DataFrame(avg_w2v_list)\n",
    "#             print(df.head())\n",
    "            print(\"W2V: \", df.shape)\n",
    "            return df\n",
    "        else:\n",
    "            return X\n",
    "        \n",
    "class ToDataFrameTransformer(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        df = pd.DataFrame(X)\n",
    "#         print(df.head())\n",
    "        print(\"TDFT: \", df.shape)\n",
    "        return df\n",
    "        \n",
    "class DropTextTransformer(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, text_col=None):\n",
    "        self.text_col = text_col\n",
    "        \n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        if self.text_col:\n",
    "            df = X.drop(self.text_col, axis=1)\n",
    "            print(\"DTT: \", df.shape)\n",
    "            return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Content-Based Recommender System\n",
    "\n",
    "### This recommender is based on Yelp reviews on cafes near the San Francisco Bay Area"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### For local computer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_best = joblib.load('../data/df_best')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### For AWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_best = joblib.load('/home/plim0793/fletcher/df_best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4155, 303)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_best.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Separate the rating and name columns from the 300 dimensional space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_rn = df_best[['name', 'rating', 'reviews']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/plim0793/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "df_rn['name'] = df_rn['name'].apply(lambda x: re.sub('[0-9]*_', '', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>rating</th>\n",
       "      <th>reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FourBarrelCoffee</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Best coffee, hands down. Parking is a challeng...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FourBarrelCoffee</td>\n",
       "      <td>5.0</td>\n",
       "      <td>One of the best almond milk lattes Ive ever ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FourBarrelCoffee</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Great hole-in-the-wall coffee spot. Good coffe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FourBarrelCoffee</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Gibraltar ReviewThe Pour:Very good, beans are ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FourBarrelCoffee</td>\n",
       "      <td>4.0</td>\n",
       "      <td>TOP notch coffee and the most AMAZING fresh pa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               name  rating                                            reviews\n",
       "0  FourBarrelCoffee     5.0  Best coffee, hands down. Parking is a challeng...\n",
       "1  FourBarrelCoffee     5.0  One of the best almond milk lattes Ive ever ha...\n",
       "2  FourBarrelCoffee     4.0  Great hole-in-the-wall coffee spot. Good coffe...\n",
       "3  FourBarrelCoffee     4.0  Gibraltar ReviewThe Pour:Very good, beans are ...\n",
       "4  FourBarrelCoffee     4.0  TOP notch coffee and the most AMAZING fresh pa..."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_300 = df_best[[i for i in range(1,301)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "arr_300 = np.array(df_300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the Google word2vec model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### For local computer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-05-30 21:48:49,708 : INFO : loading projection weights from ~/Documents/GoogleNews-vectors-negative300.bin.gz\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/plim0793/Documents/GoogleNews-vectors-negative300.bin.gz'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-0b01f1327aa5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# ONLY RUN ONCE AT THE START OF THE KERNEL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mw2v\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKeyedVectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_word2vec_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"~/Documents/GoogleNews-vectors-negative300.bin.gz\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/plim0793/anaconda3/lib/python3.6/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mload_word2vec_format\u001b[0;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"loading projection weights from %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msmart_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m             \u001b[0mheader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_unicode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m             \u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvector_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# throws for invalid file format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/plim0793/anaconda3/lib/python3.6/site-packages/smart_open/smart_open_lib.py\u001b[0m in \u001b[0;36msmart_open\u001b[0;34m(uri, mode, **kw)\u001b[0m\n\u001b[1;32m    138\u001b[0m             \u001b[0;31m# local files -- both read & write supported\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m             \u001b[0;31m# compression, if any, is determined by the filename extension (.gz, .bz2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfile_smart_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_uri\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muri_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mparsed_uri\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscheme\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"s3\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"s3n\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"s3u\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m             \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/plim0793/anaconda3/lib/python3.6/site-packages/smart_open/smart_open_lib.py\u001b[0m in \u001b[0;36mfile_smart_open\u001b[0;34m(fname, mode)\u001b[0m\n\u001b[1;32m    642\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m     \"\"\"\n\u001b[0;32m--> 644\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcompression_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    645\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/plim0793/Documents/GoogleNews-vectors-negative300.bin.gz'"
     ]
    }
   ],
   "source": [
    "# ONLY RUN ONCE AT THE START OF THE KERNEL\n",
    "w2v = models.KeyedVectors.load_word2vec_format(\"~/Documents/GoogleNews-vectors-negative300.bin.gz\",binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### For AWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-05-31 02:30:50,891 : INFO : loading projection weights from /home/plim0793/GoogleNews-vectors-negative300.bin.gz\n"
     ]
    }
   ],
   "source": [
    "# ONLY RUN ONCE AT THE START OF THE KERNEL\n",
    "w2v = models.KeyedVectors.load_word2vec_format(\"/home/plim0793/GoogleNews-vectors-negative300.bin.gz\",binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the pipeline to fit and transform the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pipe_w2v = Pipeline([\n",
    "                    ('combined_features', FeatureUnion([\n",
    "\n",
    "                        ('num_feat', SeparateFeaturesTransformer(num_cols=['rating'])),\n",
    "                        ('text_feat', Pipeline([\n",
    "\n",
    "                            ('split_text', SeparateFeaturesTransformer(text_cols=['reviews'])),\n",
    "                            ('clean', CleanTextTransformer('reviews')),\n",
    "                            ('sentiment', SentimentTransformer(text_col='clean_reviews')),\n",
    "                            ('vectorize', Word2VecTransformer(text_col='clean_reviews', w2v=w2v))\n",
    "                                                ]))\n",
    "                                                        ]))\n",
    "                    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the LSH Forest algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lsh = LSHForest(n_neighbors=5, n_estimators=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSHForest(min_hash_match=4, n_candidates=50, n_estimators=50, n_neighbors=5,\n",
       "     radius=1.0, radius_cutoff_ratio=0.9, random_state=None)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsh.fit(df_300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Provide a sample input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sample_input = [\"good coffee and quiet setting and fast wifi\"]\n",
    "sample_df = pd.DataFrame(sample_input, columns=[\"sample\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the pipeline to fit and transform the sample input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipe_sample = Pipeline([\n",
    "                        ('split_text', SeparateFeaturesTransformer(text_cols=['sample'])),\n",
    "                        ('clean', CleanTextTransformer('sample')),\n",
    "                        ('sentiment', SentimentTransformer(text_col='clean_reviews')),\n",
    "                        ('vectorize', Word2VecTransformer(text_col='clean_reviews', w2v=w2v))\n",
    "                                            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SFT:  (1, 1)\n",
      "CTT:  (1, 1)\n",
      "ST:  (1, 3)\n",
      "W2V:  (1, 300)\n"
     ]
    }
   ],
   "source": [
    "sample_transform = pipe_sample.fit_transform(sample_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the 20 nearest reviews for a sample input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "distances, indices = lsh.kneighbors(sample_transform, n_neighbors=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_nearest(indices, distances, df):\n",
    "    df_temp = df.loc[indices, ['rating','name','reviews']]\n",
    "    df_temp['dist'] = distances\n",
    "    df_temp = df_temp.sort_values(['dist'], ascending=False)\n",
    "    df_temp = df_temp.reset_index()\n",
    "    return df_temp\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>rating</th>\n",
       "      <th>name</th>\n",
       "      <th>reviews</th>\n",
       "      <th>dist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3702</td>\n",
       "      <td>2.0</td>\n",
       "      <td>167_ParamoCoffeeCompany</td>\n",
       "      <td>I got a decaf coffee to go with my onigiri fro...</td>\n",
       "      <td>0.008356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35105</td>\n",
       "      <td>3.0</td>\n",
       "      <td>732_WholeFoodsMarketSteepBrew</td>\n",
       "      <td>wish they had diet coke. not bad food, but kin...</td>\n",
       "      <td>0.008308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35132</td>\n",
       "      <td>3.0</td>\n",
       "      <td>732_WholeFoodsMarketSteepBrew</td>\n",
       "      <td>wish they had diet coke. not bad food, but kin...</td>\n",
       "      <td>0.008308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33434</td>\n",
       "      <td>4.0</td>\n",
       "      <td>701_SunRiseRestaurant</td>\n",
       "      <td>This place is pretty good. Service is friendly...</td>\n",
       "      <td>0.008300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34697</td>\n",
       "      <td>5.0</td>\n",
       "      <td>724_HotCookie</td>\n",
       "      <td>Not only is this place fun and in a great loca...</td>\n",
       "      <td>0.008286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2880</td>\n",
       "      <td>5.0</td>\n",
       "      <td>151_RedDoorCoffee</td>\n",
       "      <td>Art and coffee - good mix.  the coffee is quit...</td>\n",
       "      <td>0.008271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>33229</td>\n",
       "      <td>4.0</td>\n",
       "      <td>699_CafePacifica</td>\n",
       "      <td>BOMB bagel sandwich and latte, like so good I'...</td>\n",
       "      <td>0.008144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>38725</td>\n",
       "      <td>4.0</td>\n",
       "      <td>798_TheGoldenWest</td>\n",
       "      <td>a hidden gem.  a bit pricey, but some of the b...</td>\n",
       "      <td>0.008068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>11500</td>\n",
       "      <td>5.0</td>\n",
       "      <td>307_Faye’sVideo&amp;EspressoBar</td>\n",
       "      <td>Videos and coffee is a brilliant combination, ...</td>\n",
       "      <td>0.008031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7678</td>\n",
       "      <td>5.0</td>\n",
       "      <td>238_PhilzCoffee</td>\n",
       "      <td>Much better than Starbucks and peets. Choosing...</td>\n",
       "      <td>0.008018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5827</td>\n",
       "      <td>5.0</td>\n",
       "      <td>204_PhilzCoffee</td>\n",
       "      <td>Much better than Starbucks and peets. Choosing...</td>\n",
       "      <td>0.008018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>37703</td>\n",
       "      <td>5.0</td>\n",
       "      <td>77_PiccoloPetesCafe</td>\n",
       "      <td>The almond  french toast  here is fluffy and j...</td>\n",
       "      <td>0.007849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>37746</td>\n",
       "      <td>5.0</td>\n",
       "      <td>77_PiccoloPetesCafe</td>\n",
       "      <td>The almond  french toast  here is fluffy and j...</td>\n",
       "      <td>0.007849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>12538</td>\n",
       "      <td>4.0</td>\n",
       "      <td>325_CafédelaPresse</td>\n",
       "      <td>Right outside of Chinatown. Cute and quaint sp...</td>\n",
       "      <td>0.007698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>6679</td>\n",
       "      <td>3.0</td>\n",
       "      <td>21_CraftsmanandWolves</td>\n",
       "      <td>Finally made it here for a rebel within. It is...</td>\n",
       "      <td>0.007439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>7763</td>\n",
       "      <td>5.0</td>\n",
       "      <td>23_Zo11Coffee</td>\n",
       "      <td>Coffee is good and wifi is fast. Quiet, perfec...</td>\n",
       "      <td>0.007391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>9699</td>\n",
       "      <td>1.0</td>\n",
       "      <td>274_VerveCoffeeRoasters</td>\n",
       "      <td>They do not have functioning wifi.  Before pur...</td>\n",
       "      <td>0.007062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>9663</td>\n",
       "      <td>1.0</td>\n",
       "      <td>274_VerveCoffeeRoasters</td>\n",
       "      <td>They do not have functioning wifi.  Before pur...</td>\n",
       "      <td>0.007062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>12944</td>\n",
       "      <td>4.0</td>\n",
       "      <td>332_RoCafe</td>\n",
       "      <td>Mint on nachos? I'm down! Interesting &amp; delici...</td>\n",
       "      <td>0.006837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>16691</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3_SightglassCoffee</td>\n",
       "      <td>Good coffee and nice environment at the trade ...</td>\n",
       "      <td>0.005737</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index  rating                           name  \\\n",
       "0    3702     2.0        167_ParamoCoffeeCompany   \n",
       "1   35105     3.0  732_WholeFoodsMarketSteepBrew   \n",
       "2   35132     3.0  732_WholeFoodsMarketSteepBrew   \n",
       "3   33434     4.0          701_SunRiseRestaurant   \n",
       "4   34697     5.0                  724_HotCookie   \n",
       "5    2880     5.0              151_RedDoorCoffee   \n",
       "6   33229     4.0               699_CafePacifica   \n",
       "7   38725     4.0              798_TheGoldenWest   \n",
       "8   11500     5.0    307_Faye’sVideo&EspressoBar   \n",
       "9    7678     5.0                238_PhilzCoffee   \n",
       "10   5827     5.0                204_PhilzCoffee   \n",
       "11  37703     5.0            77_PiccoloPetesCafe   \n",
       "12  37746     5.0            77_PiccoloPetesCafe   \n",
       "13  12538     4.0             325_CafédelaPresse   \n",
       "14   6679     3.0          21_CraftsmanandWolves   \n",
       "15   7763     5.0                  23_Zo11Coffee   \n",
       "16   9699     1.0        274_VerveCoffeeRoasters   \n",
       "17   9663     1.0        274_VerveCoffeeRoasters   \n",
       "18  12944     4.0                     332_RoCafe   \n",
       "19  16691     2.0             3_SightglassCoffee   \n",
       "\n",
       "                                              reviews      dist  \n",
       "0   I got a decaf coffee to go with my onigiri fro...  0.008356  \n",
       "1   wish they had diet coke. not bad food, but kin...  0.008308  \n",
       "2   wish they had diet coke. not bad food, but kin...  0.008308  \n",
       "3   This place is pretty good. Service is friendly...  0.008300  \n",
       "4   Not only is this place fun and in a great loca...  0.008286  \n",
       "5   Art and coffee - good mix.  the coffee is quit...  0.008271  \n",
       "6   BOMB bagel sandwich and latte, like so good I'...  0.008144  \n",
       "7   a hidden gem.  a bit pricey, but some of the b...  0.008068  \n",
       "8   Videos and coffee is a brilliant combination, ...  0.008031  \n",
       "9   Much better than Starbucks and peets. Choosing...  0.008018  \n",
       "10  Much better than Starbucks and peets. Choosing...  0.008018  \n",
       "11  The almond  french toast  here is fluffy and j...  0.007849  \n",
       "12  The almond  french toast  here is fluffy and j...  0.007849  \n",
       "13  Right outside of Chinatown. Cute and quaint sp...  0.007698  \n",
       "14  Finally made it here for a rebel within. It is...  0.007439  \n",
       "15  Coffee is good and wifi is fast. Quiet, perfec...  0.007391  \n",
       "16  They do not have functioning wifi.  Before pur...  0.007062  \n",
       "17  They do not have functioning wifi.  Before pur...  0.007062  \n",
       "18  Mint on nachos? I'm down! Interesting & delici...  0.006837  \n",
       "19  Good coffee and nice environment at the trade ...  0.005737  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample_rec = get_nearest(indices[0], distances[0], df_rn)\n",
    "df_sample_rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "167_ParamoCoffeeCompany\n",
      "NUMBER 0:  I got a decaf coffee to go with my onigiri from next door. It was ok. The barista was very nice and helpful but the coffee did not taste that good.\n",
      "\n",
      "\n",
      "732_WholeFoodsMarketSteepBrew\n",
      "NUMBER 1:  wish they had diet coke. not bad food, but kind of strange offerings.neat ordering system.\n",
      "\n",
      "\n",
      "732_WholeFoodsMarketSteepBrew\n",
      "NUMBER 2:  wish they had diet coke. not bad food, but kind of strange offerings.neat ordering system.\n",
      "\n",
      "\n",
      "701_SunRiseRestaurant\n",
      "NUMBER 3:  This place is pretty good. Service is friendly but not fast. Food is pretty standard cafe food. I got an omelet which took a little while to get here but was piping hot and fresh. Coffee tasted a bit burnt but was quickly refilled after I finished it.\n",
      "\n",
      "\n",
      "724_HotCookie\n",
      "NUMBER 4:  Not only is this place fun and in a great location. The fact that its open late and still offers amazing tasting cookies(regular or fun shaped) and amazing dipped brownies(best friend with milk) just adds to a new fun sweet addiction. AND you can get it delivered through postdates! Definite plus for late night munchies!\n",
      "\n",
      "\n",
      "151_RedDoorCoffee\n",
      "NUMBER 5:  Art and coffee - good mix.  the coffee is quite tasty, seating sufficient and the ambience pretty solid.\n",
      "\n",
      "\n",
      "699_CafePacifica\n",
      "NUMBER 6:  BOMB bagel sandwich and latte, like so good I'd dream about it. A star off since its a bit overpriced, limited indoor seating and hard to find parking. But outside seating is great and it's right by the water (no view though).\n",
      "\n",
      "\n",
      "798_TheGoldenWest\n",
      "NUMBER 7:  a hidden gem.  a bit pricey, but some of the best quality and most unique sandwiches and salads in the area. no seating - just a takeout window.\n",
      "\n",
      "\n",
      "307_Faye’sVideo&EspressoBar\n",
      "NUMBER 8:  Videos and coffee is a brilliant combination, and there's no bigger affirmation than winning the guess-the-theme-of-the-videos-in-this-group contest.\n",
      "\n",
      "\n",
      "238_PhilzCoffee\n",
      "NUMBER 9:  Much better than Starbucks and peets. Choosing a coffee can be daunting but I just picked anything and it's usually good and interesting.  A word of warning - a lot of drinks have minty taste because it comes with mint leaves ( or not sure what it is ) so if you don't like mint,ask first before ordering\n",
      "\n",
      "\n",
      "204_PhilzCoffee\n",
      "NUMBER 10:  Much better than Starbucks and peets. Choosing a coffee can be daunting but I just picked anything and it's usually good and interesting.  A word of warning - a lot of drinks have minty taste because it comes with mint leaves ( or not sure what it is ) so if you don't like mint,ask first before ordering\n",
      "\n",
      "\n",
      "77_PiccoloPetesCafe\n",
      "NUMBER 11:  The almond  french toast  here is fluffy and just the right amount of a  sweet treat. It's a hidden gem in the  city with delicious  coffee drinks and unique breakfast  bites. Grab a group , head down and order one of each off the menu. ..you won't be disappointed. Enjoy :)\n",
      "\n",
      "\n",
      "77_PiccoloPetesCafe\n",
      "NUMBER 12:  The almond  french toast  here is fluffy and just the right amount of a  sweet treat. It's a hidden gem in the  city with delicious  coffee drinks and unique breakfast  bites. Grab a group , head down and order one of each off the menu. ..you won't be disappointed. Enjoy :)\n",
      "\n",
      "\n",
      "325_CafédelaPresse\n",
      "NUMBER 13:  Right outside of Chinatown. Cute and quaint spot for a bite to eat and a more intimate setting in the dining room. Iced coffee is amazing. Ordered French onion soup and flatbread with capers and salmon.\n",
      "\n",
      "\n",
      "21_CraftsmanandWolves\n",
      "NUMBER 14:  Finally made it here for a rebel within. It is definitely a cool idea and it was fun to cut open the muffin and find the egg. But I didn't think the muffin was all that great. So, 5 stars for creativity and magic.\n",
      "\n",
      "\n",
      "23_Zo11Coffee\n",
      "NUMBER 15:  Coffee is good and wifi is fast. Quiet, perfect spot to get work done on a Sunday morning.\n",
      "\n",
      "\n",
      "274_VerveCoffeeRoasters\n",
      "NUMBER 16:  They do not have functioning wifi.  Before purchasing I asked directly if they had wifi and the woman at the counter said yes. Then after sitting I asked other employees and they said they didn't have wifi. I don't need wifi if I'm just hanging out and I'm fine if a place does not have wifi. Just let me know at the beginning so I can find a place with wifi.\n",
      "\n",
      "\n",
      "274_VerveCoffeeRoasters\n",
      "NUMBER 17:  They do not have functioning wifi.  Before purchasing I asked directly if they had wifi and the woman at the counter said yes. Then after sitting I asked other employees and they said they didn't have wifi. I don't need wifi if I'm just hanging out and I'm fine if a place does not have wifi. Just let me know at the beginning so I can find a place with wifi.\n",
      "\n",
      "\n",
      "332_RoCafe\n",
      "NUMBER 18:  Mint on nachos? I'm down! Interesting & delicious food, big portions, super nice staff/owner. The decor's kind of odd, it was a little too quiet for comfort (granted, I went at an odd time of the day), and it was humid up in there, but the food definitely made up for it.\n",
      "\n",
      "\n",
      "3_SightglassCoffee\n",
      "NUMBER 19:  Good coffee and nice environment at the trade off of no wifi, limited seating, and rude, unsympathetic staff.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(df_sample_rec)):\n",
    "    print(df_sample_rec.loc[i, 'name'])\n",
    "    print(\"NUMBER \" + str(i) + \": \", df_sample_rec.loc[i, 'reviews'])\n",
    "    print(\"\\n\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
