{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a Content-Based Recommender System\n",
    "\n",
    "Paul Lim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/plim0793/anaconda/lib/python3.5/site-packages/nltk/twitter/__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
      "  warnings.warn(\"The twython library has not been installed. \"\n"
     ]
    }
   ],
   "source": [
    "# Main imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "\n",
    "# sklearn\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics.pairwise import manhattan_distances\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from sklearn.externals import joblib\n",
    "from sklearn import pipeline, feature_selection, decomposition\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.cluster import DBSCAN, AgglomerativeClustering, Birch\n",
    "from sklearn.neighbors import NearestNeighbors, LSHForest\n",
    "\n",
    "# NLP \n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from textblob import TextBlob\n",
    "import spacy\n",
    "import gensim\n",
    "from gensim import models\n",
    "from gensim.models import word2vec\n",
    "import snowballstemmer\n",
    "\n",
    "# Misc.\n",
    "import re\n",
    "import datetime\n",
    "import time\n",
    "import logging\n",
    "import math\n",
    "\n",
    "% matplotlib inline\n",
    "\n",
    "sns.set_style(\"white\")\n",
    "sns.set_style('ticks')\n",
    "sns.set_style({'xtick.direction': u'in', 'ytick.direction': u'in'})\n",
    "sns.set_style({'legend.frameon': True})\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions/Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataframeToSeriesTransformer(BaseEstimator, TransformerMixin):\n",
    "        \n",
    "    def __init__(self, col=None):\n",
    "        self.col = col\n",
    "    \n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        if self.col:\n",
    "            print(\"DTST: \", X[self.col].shape)\n",
    "            return X[self.col]\n",
    "        else:\n",
    "            return X\n",
    "        \n",
    "class SeparateFeaturesTransformer(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, num_cols=None, text_cols=None):\n",
    "        self.num_cols = num_cols\n",
    "        self.text_cols = text_cols\n",
    "        \n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        if self.num_cols:\n",
    "            print(\"SFT: \", X.loc[:, self.num_cols].shape)\n",
    "            return X.loc[:, self.num_cols]\n",
    "        elif self.text_cols:\n",
    "            print(\"SFT: \", X.loc[:, self.text_cols].shape)\n",
    "            return X.loc[:, self.text_cols]\n",
    "        else:\n",
    "            return X\n",
    "        \n",
    "class WilsonAverageTransformer(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, num_col=None, biz_list=None):\n",
    "        self.num_col = num_col\n",
    "        self.biz_list = biz_list\n",
    "    \n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        if self.num_col and self.biz_list.all():\n",
    "            scores = get_average_rating(X, self.biz_list)\n",
    "            \n",
    "            X_avg = pd.DataFrame({'average': scores})\n",
    "            print(\"WAT: \", X_avg.shape)\n",
    "            return X_avg\n",
    "        else:\n",
    "            return X\n",
    "        \n",
    "class CleanTextTransformer(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self, text_col=None):\n",
    "        self.text_col = text_col\n",
    "        \n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "\n",
    "        X_list = X.loc[:, self.text_col].tolist()\n",
    "        \n",
    "        if self.text_col:\n",
    "            df = pd.DataFrame()\n",
    "            clean_review_list = []\n",
    "            \n",
    "            for review in X_list:\n",
    "                clean_review = ''\n",
    "                \n",
    "                for word in TextBlob(review).words:\n",
    "                    clean_review += word.lemmatize() + ' '\n",
    "                        \n",
    "                clean_review_list.append(clean_review)\n",
    "                        \n",
    "            df['clean_reviews'] = clean_review_list\n",
    "            print(\"CTT: \", df.shape)\n",
    "            return df\n",
    "        else:\n",
    "            return X\n",
    "        \n",
    "class DensifyTransformer(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        df = pd.DataFrame(X.toarray())\n",
    "        print(\"DT: \", df.shape)\n",
    "        return df\n",
    "    \n",
    "class SentimentTransformer(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, text_col=None):\n",
    "        self.text_col = text_col\n",
    "    \n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        if self.text_col:\n",
    "            df = pd.DataFrame()\n",
    "            sum_pol_list = []\n",
    "            sum_sub_list = []\n",
    "\n",
    "            for doc in X.loc[:, self.text_col]:\n",
    "                sum_pol = 0\n",
    "                sum_sub = 0\n",
    "                doc_blob = TextBlob(doc)\n",
    "\n",
    "                for sent in doc_blob.sentences:\n",
    "                    sum_pol += sent.sentiment[0]\n",
    "                    sum_sub += sent.sentiment[1]\n",
    "\n",
    "                sum_pol_list.append(sum_pol)\n",
    "                sum_sub_list.append(sum_sub)\n",
    "\n",
    "            df['pol'] = sum_pol_list\n",
    "            df['sub'] = sum_sub_list\n",
    "            df['clean_reviews'] = X.loc[:, self.text_col] # Need to keep the clean reviews for the W2V transformer.\n",
    "            print(\"ST: \", df.shape)\n",
    "            return df\n",
    "        else:\n",
    "            return X\n",
    "\n",
    "class Word2VecTransformer(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, text_col=None, w2v=None):\n",
    "        self.text_col = text_col\n",
    "        self.w2v = w2v\n",
    "        \n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        if self.text_col:\n",
    "            avg_w2v_list = []\n",
    "            \n",
    "            for review in X.loc[:, self.text_col]:\n",
    "                avg_w2v = np.zeros(300)\n",
    "                count = 0\n",
    "                \n",
    "                for word in review:\n",
    "                    try:\n",
    "                        avg_w2v += w2v.word_vec(word)\n",
    "                        count += 1\n",
    "                    except Exception:\n",
    "                        continue\n",
    "\n",
    "                avg_w2v_list.append(avg_w2v/count)\n",
    "            df = pd.DataFrame(avg_w2v_list)\n",
    "#             print(df.head())\n",
    "            print(\"W2V: \", df.shape)\n",
    "            return df\n",
    "        else:\n",
    "            return X\n",
    "        \n",
    "class ToDataFrameTransformer(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        df = pd.DataFrame(X)\n",
    "#         print(df.head())\n",
    "        print(\"TDFT: \", df.shape)\n",
    "        return df\n",
    "        \n",
    "class DropTextTransformer(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, text_col=None):\n",
    "        self.text_col = text_col\n",
    "        \n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        if self.text_col:\n",
    "            df = X.drop(self.text_col, axis=1)\n",
    "            print(\"DTT: \", df.shape)\n",
    "            return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Content-Based Recommender System\n",
    "\n",
    "### This recommender is based on Yelp reviews on cafes near the San Francisco Bay Area"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### For local computer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_best = joblib.load('../data/df_best')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### For AWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_best = joblib.load('/home/plim0793/fletcher/df_best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4155, 303)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_best.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Separate the rating and name columns from the 300 dimensional space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_rn = df_best[['name', 'rating', 'reviews']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/plim0793/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "df_rn['name'] = df_rn['name'].apply(lambda x: re.sub('[0-9]*_', '', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>rating</th>\n",
       "      <th>reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FourBarrelCoffee</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Best coffee, hands down. Parking is a challeng...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FourBarrelCoffee</td>\n",
       "      <td>5.0</td>\n",
       "      <td>One of the best almond milk lattes Ive ever ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FourBarrelCoffee</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Great hole-in-the-wall coffee spot. Good coffe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FourBarrelCoffee</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Gibraltar ReviewThe Pour:Very good, beans are ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FourBarrelCoffee</td>\n",
       "      <td>4.0</td>\n",
       "      <td>TOP notch coffee and the most AMAZING fresh pa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               name  rating                                            reviews\n",
       "0  FourBarrelCoffee     5.0  Best coffee, hands down. Parking is a challeng...\n",
       "1  FourBarrelCoffee     5.0  One of the best almond milk lattes Ive ever ha...\n",
       "2  FourBarrelCoffee     4.0  Great hole-in-the-wall coffee spot. Good coffe...\n",
       "3  FourBarrelCoffee     4.0  Gibraltar ReviewThe Pour:Very good, beans are ...\n",
       "4  FourBarrelCoffee     4.0  TOP notch coffee and the most AMAZING fresh pa..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_300 = df_best[[i for i in range(1,301)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "arr_300 = np.array(df_300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the Google word2vec model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### For local computer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-06-01 16:47:03,016 : INFO : loading projection weights from ~/Documents/GoogleNews-vectors-negative300.bin.gz\n",
      "2017-06-01 16:50:28,675 : INFO : loaded (3000000, 300) matrix from ~/Documents/GoogleNews-vectors-negative300.bin.gz\n"
     ]
    }
   ],
   "source": [
    "# ONLY RUN ONCE AT THE START OF THE KERNEL\n",
    "w2v = models.KeyedVectors.load_word2vec_format(\"~/Documents/GoogleNews-vectors-negative300.bin.gz\",binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### For AWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-05-31 02:30:50,891 : INFO : loading projection weights from /home/plim0793/GoogleNews-vectors-negative300.bin.gz\n"
     ]
    }
   ],
   "source": [
    "# ONLY RUN ONCE AT THE START OF THE KERNEL\n",
    "w2v = models.KeyedVectors.load_word2vec_format(\"/home/plim0793/GoogleNews-vectors-negative300.bin.gz\",binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the LSH Forest algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsh = LSHForest(n_neighbors=5, n_estimators=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSHForest(min_hash_match=4, n_candidates=50, n_estimators=50, n_neighbors=5,\n",
       "     radius=1.0, radius_cutoff_ratio=0.9, random_state=None)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsh.fit(df_300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Provide a sample input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_input = [\"good coffee and quiet setting and fast wifi\"]\n",
    "sample_df = pd.DataFrame(sample_input, columns=[\"sample\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the pipeline to fit and transform the sample input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipe_sample = Pipeline([\n",
    "                        ('split_text', SeparateFeaturesTransformer(text_cols=['sample'])),\n",
    "                        ('clean', CleanTextTransformer('sample')),\n",
    "                        ('sentiment', SentimentTransformer(text_col='clean_reviews')),\n",
    "                        ('vectorize', Word2VecTransformer(text_col='clean_reviews', w2v=w2v))\n",
    "                                            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SFT:  (1, 1)\n",
      "CTT:  (1, 1)\n",
      "ST:  (1, 3)\n",
      "W2V:  (1, 300)\n"
     ]
    }
   ],
   "source": [
    "sample_transform = pipe_sample.fit_transform(sample_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the 20 nearest reviews for a sample input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances, indices = lsh.kneighbors(sample_transform, n_neighbors=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_nearest(indices, distances, df):\n",
    "    df_temp = df.loc[indices, ['rating','name','reviews']]\n",
    "    df_temp['dist'] = distances\n",
    "    df_temp = df_temp.sort_values(['dist'], ascending=False)\n",
    "    df_temp = df_temp.drop_duplicates()\n",
    "    df_temp = df_temp.reset_index()\n",
    "    return df_temp\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>rating</th>\n",
       "      <th>name</th>\n",
       "      <th>reviews</th>\n",
       "      <th>dist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>346</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Beanery</td>\n",
       "      <td>This neighborhood is filled with amazingly goo...</td>\n",
       "      <td>0.011694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3794</td>\n",
       "      <td>2.0</td>\n",
       "      <td>CaffeStrada</td>\n",
       "      <td>Coffee tastes lousy.  If it weren't for the ni...</td>\n",
       "      <td>0.011595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1239</td>\n",
       "      <td>4.0</td>\n",
       "      <td>DarwinCafe</td>\n",
       "      <td>Great lunch spot, though line gets long right ...</td>\n",
       "      <td>0.011468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3560</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Joey&amp;Pat’sItalianBakery&amp;Cafe</td>\n",
       "      <td>I had a ground beef/croissanty thing, it was g...</td>\n",
       "      <td>0.011299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1402</td>\n",
       "      <td>4.0</td>\n",
       "      <td>CafeCoco</td>\n",
       "      <td>I don't give a shit if you think the food is m...</td>\n",
       "      <td>0.011167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1729</td>\n",
       "      <td>4.0</td>\n",
       "      <td>RitualCoffeeRoasters</td>\n",
       "      <td>Damn good coffee!  That's the most important t...</td>\n",
       "      <td>0.011157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3185</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Starbucks</td>\n",
       "      <td>Don't get hung up on it being the big bad chai...</td>\n",
       "      <td>0.010904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>804</td>\n",
       "      <td>5.0</td>\n",
       "      <td>TaylorStreetCoffeeShop</td>\n",
       "      <td>Breakfast - eggs Benedict was good. Portion si...</td>\n",
       "      <td>0.010894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>176</td>\n",
       "      <td>2.0</td>\n",
       "      <td>farm:table</td>\n",
       "      <td>Disappointed. Insisted to the hubs we go here ...</td>\n",
       "      <td>0.010868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3672</td>\n",
       "      <td>4.0</td>\n",
       "      <td>TheManor</td>\n",
       "      <td>Thorough impressed with the renovations and ne...</td>\n",
       "      <td>0.010865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>204</td>\n",
       "      <td>4.0</td>\n",
       "      <td>ReposeCoffeeBar</td>\n",
       "      <td>Friendly atmosphere and delicious coffee! I th...</td>\n",
       "      <td>0.010769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1275</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CafeStJorge</td>\n",
       "      <td>Cafe St. Jorge has the nicest, most edible, mo...</td>\n",
       "      <td>0.010758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>158</td>\n",
       "      <td>4.0</td>\n",
       "      <td>TroubleCoffeeCompany</td>\n",
       "      <td>Had a cup of coffee while we were waiting for ...</td>\n",
       "      <td>0.010648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2989</td>\n",
       "      <td>4.0</td>\n",
       "      <td>BioCafe</td>\n",
       "      <td>We had the salmon, basil and cheese sandwich. ...</td>\n",
       "      <td>0.010391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3364</td>\n",
       "      <td>5.0</td>\n",
       "      <td>AllStarDonuts</td>\n",
       "      <td>Best sugar donuts I've had in my entire life h...</td>\n",
       "      <td>0.010276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2901</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Rocco’sCafé</td>\n",
       "      <td>It is decent diner food.  I would have voted h...</td>\n",
       "      <td>0.009959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>992</td>\n",
       "      <td>5.0</td>\n",
       "      <td>VinylCoffee&amp;WineBar</td>\n",
       "      <td>Friendly staff, great music and coffee--can't ...</td>\n",
       "      <td>0.009865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1541</td>\n",
       "      <td>4.0</td>\n",
       "      <td>FreshBayCafe</td>\n",
       "      <td>This quaint little cafe was a nice surprised! ...</td>\n",
       "      <td>0.009332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2401</td>\n",
       "      <td>2.0</td>\n",
       "      <td>LatteExpress</td>\n",
       "      <td>This place has two things going for it... it's...</td>\n",
       "      <td>0.009001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2889</td>\n",
       "      <td>4.0</td>\n",
       "      <td>DiamondCafe</td>\n",
       "      <td>Fast, efficient and friendly. The food is tast...</td>\n",
       "      <td>0.007873</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index  rating                          name  \\\n",
       "0     346     4.0                       Beanery   \n",
       "1    3794     2.0                   CaffeStrada   \n",
       "2    1239     4.0                    DarwinCafe   \n",
       "3    3560     3.0  Joey&Pat’sItalianBakery&Cafe   \n",
       "4    1402     4.0                      CafeCoco   \n",
       "5    1729     4.0          RitualCoffeeRoasters   \n",
       "6    3185     4.0                     Starbucks   \n",
       "7     804     5.0        TaylorStreetCoffeeShop   \n",
       "8     176     2.0                    farm:table   \n",
       "9    3672     4.0                      TheManor   \n",
       "10    204     4.0               ReposeCoffeeBar   \n",
       "11   1275     5.0                   CafeStJorge   \n",
       "12    158     4.0          TroubleCoffeeCompany   \n",
       "13   2989     4.0                       BioCafe   \n",
       "14   3364     5.0                 AllStarDonuts   \n",
       "15   2901     3.0                   Rocco’sCafé   \n",
       "16    992     5.0           VinylCoffee&WineBar   \n",
       "17   1541     4.0                  FreshBayCafe   \n",
       "18   2401     2.0                  LatteExpress   \n",
       "19   2889     4.0                   DiamondCafe   \n",
       "\n",
       "                                              reviews      dist  \n",
       "0   This neighborhood is filled with amazingly goo...  0.011694  \n",
       "1   Coffee tastes lousy.  If it weren't for the ni...  0.011595  \n",
       "2   Great lunch spot, though line gets long right ...  0.011468  \n",
       "3   I had a ground beef/croissanty thing, it was g...  0.011299  \n",
       "4   I don't give a shit if you think the food is m...  0.011167  \n",
       "5   Damn good coffee!  That's the most important t...  0.011157  \n",
       "6   Don't get hung up on it being the big bad chai...  0.010904  \n",
       "7   Breakfast - eggs Benedict was good. Portion si...  0.010894  \n",
       "8   Disappointed. Insisted to the hubs we go here ...  0.010868  \n",
       "9   Thorough impressed with the renovations and ne...  0.010865  \n",
       "10  Friendly atmosphere and delicious coffee! I th...  0.010769  \n",
       "11  Cafe St. Jorge has the nicest, most edible, mo...  0.010758  \n",
       "12  Had a cup of coffee while we were waiting for ...  0.010648  \n",
       "13  We had the salmon, basil and cheese sandwich. ...  0.010391  \n",
       "14  Best sugar donuts I've had in my entire life h...  0.010276  \n",
       "15  It is decent diner food.  I would have voted h...  0.009959  \n",
       "16  Friendly staff, great music and coffee--can't ...  0.009865  \n",
       "17  This quaint little cafe was a nice surprised! ...  0.009332  \n",
       "18  This place has two things going for it... it's...  0.009001  \n",
       "19  Fast, efficient and friendly. The food is tast...  0.007873  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample_rec = get_nearest(indices[0], distances[0], df_rn)\n",
    "df_sample_rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beanery\n",
      "NUMBER 0:  This neighborhood is filled with amazingly good coffee options. Loved their latte. It makes waiting for the Muni so much better!\n",
      "\n",
      "\n",
      "CaffeStrada\n",
      "NUMBER 1:  Coffee tastes lousy.  If it weren't for the nice outdoor setting, I'd give it one star.  Problem is, not much good coffee in the vicinity.  Americano so bad, almost made me a tea drinker!\n",
      "\n",
      "\n",
      "DarwinCafe\n",
      "NUMBER 2:  Great lunch spot, though line gets long right after noon and there is limited seating on premise. Beautiful salads and somewhat limited selection of hearty sandwiches w side salad. Cold smoked trout w horseradish aioli was great, though more like tuna salad sandwich than fish filets that I was expecting.\n",
      "\n",
      "\n",
      "Joey&Pat’sItalianBakery&Cafe\n",
      "NUMBER 3:  I had a ground beef/croissanty thing, it was good.  Strong hot coffee.  It was weird using the bathroom with the back door left open, but nobody came in so it's all good.  A lot of flies inside, that I wasn't so thrilled with.  The staff were very nice.  I wouldn't make a special trip back.\n",
      "\n",
      "\n",
      "CafeCoco\n",
      "NUMBER 4:  I don't give a shit if you think the food is meh or the coffee isn't as good as you think it should be. I think it's fine. I come here because my internet at home takes 6 hours to load a 2 minute video and it takes only a few minutes to load it here. The tables are big, it's spacious, music is kinda loud, but no one bothers you. This is a good place to get stuff done if you can stand the loudness of the music.**UPDATE**Owner messaged me and told me she would turn down the music. Sure thing the next day I went in there to see and it was turned down**\n",
      "\n",
      "\n",
      "RitualCoffeeRoasters\n",
      "NUMBER 5:  Damn good coffee!  That's the most important thing.  But the blackberry scone I had was damn good too!  And sitting outside and enjoying them both together in SF ~that's the best!\n",
      "\n",
      "\n",
      "Starbucks\n",
      "NUMBER 6:  Don't get hung up on it being the big bad chain. The bottom line is you can get coffee done anyway you want here without getting robbed.\n",
      "\n",
      "\n",
      "TaylorStreetCoffeeShop\n",
      "NUMBER 7:  Breakfast - eggs Benedict was good. Portion size was definitely worth it. Loved that you could substitute the hash browns for salad! Millionaire bacon.. Wasn't a fan of it. If you're into sweet candied bacon, then this is definitely for you. Siracha ketchup - sounded super cool, different...but didn't love it for anything I ate though.Service - very attentive, probably because the dining area isn't huge probably only 20 seats so they want to get customers in and out in a timely manner. No wait on a Tuesday morning before 8 am. I can only imagine the wait on a weekend though...Would definitely stop by again.\n",
      "\n",
      "\n",
      "farm:table\n",
      "NUMBER 8:  Disappointed. Insisted to the hubs we go here based on the good ratings, wish we had skipped.  Very limited menu (consisting of 4 breakfast items), long wait, limited seating, & once we received our food it was bland.  Skip this one.\n",
      "\n",
      "\n",
      "TheManor\n",
      "NUMBER 9:  Thorough impressed with the renovations and new management. Food is adequate with regards to portion, but pricing is a little bit high, as you would expect from West Portal. I would have liked their staff to be a bit more attentive when it came to taking food orders and closing out a tab.\n",
      "\n",
      "\n",
      "ReposeCoffeeBar\n",
      "NUMBER 10:  Friendly atmosphere and delicious coffee! I think it's a good spot for grab and go only though.It has a few stools for sitting but definitely not the best spot to enjoy a coffee at.Very nice decor and friendly staff :) Keep up with the good work!!\n",
      "\n",
      "\n",
      "CafeStJorge\n",
      "NUMBER 11:  Cafe St. Jorge has the nicest, most edible, most original cafe menu in the city. Everything is real honest food, not gross gut bombs or the generic cafe fair of old quiche and bagels. I'm picky- I don't want big gross carb fests but I also don't want rabbit food. Think fava bean purée on sliced baguettes with fresh lemon, olive oil, sea salt and tuna (or was it sardines? I dunno but it was filling and delicious), big chia bowls with dried fruit, nuts and fresh strawberries and bananas, almond smoothies with dates and cocoa, waffles, fresh juices with ginger and other yummy flavors, Portuguese style snack plates, fig toast with ricotta and honey, avocado toasts, etc. The staff is genuinely friendly and intelligent, the iced tea has me going for hours, good lighting, newspapers, and magazines!\n",
      "\n",
      "\n",
      "TroubleCoffeeCompany\n",
      "NUMBER 12:  Had a cup of coffee while we were waiting for brunch at the neighboring restaurant. The coffee was good. Toast looked very good, next time I want to try.\n",
      "\n",
      "\n",
      "BioCafe\n",
      "NUMBER 13:  We had the salmon, basil and cheese sandwich. Very good, coffee was decent and seating was two tiny tables outside. Outdoor seating would have been better if not for construction going on right next door. Good for a take and run type of thing.\n",
      "\n",
      "\n",
      "AllStarDonuts\n",
      "NUMBER 14:  Best sugar donuts I've had in my entire life hands down. Crispy and soft and fluffy all at the same time. I get lost in these donuts. The bagel sandwiches are also a great meal option :)\n",
      "\n",
      "\n",
      "Rocco’sCafé\n",
      "NUMBER 15:  It is decent diner food.  I would have voted higher, but the country fried potatoes taste a bit fishy from the oil. Good coffee.\n",
      "\n",
      "\n",
      "VinylCoffee&WineBar\n",
      "NUMBER 16:  Friendly staff, great music and coffee--can't wait to try the food!\n",
      "\n",
      "\n",
      "FreshBayCafe\n",
      "NUMBER 17:  This quaint little cafe was a nice surprised!  The food was made with care and attention to detail.  Just looking at the food you can tell it was going taste good.  I had the pastrami on rye with Swiss was delicious!  Will definitely go back!\n",
      "\n",
      "\n",
      "LatteExpress\n",
      "NUMBER 18:  This place has two things going for it... it's cheap... and it's edible.It's definitely not good and the ingredients aren't fresh.If you like good vietnamese sandwiches, don't go here.\n",
      "\n",
      "\n",
      "DiamondCafe\n",
      "NUMBER 19:  Fast, efficient and friendly. The food is tasty and the setting can't be beat. I'm a big fan.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(df_sample_rec)):\n",
    "    print(df_sample_rec.loc[i, 'name'])\n",
    "    print(\"NUMBER \" + str(i) + \": \", df_sample_rec.loc[i, 'reviews'])\n",
    "    print(\"\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
